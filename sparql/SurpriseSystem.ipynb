{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import get_dataset_dir\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "min_movies= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_item_names():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = (line[1], line[2])\n",
    "    return rid_to_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=5):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, round(est, 3)))\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_to_console(user_id, predictions):\n",
    "    print('User ID: ', user_id)\n",
    "    for prediction in predictions:\n",
    "        print('{:4s} {:<60s} {}'.format(prediction['id'], prediction['name'], prediction['rating']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_to_file(user_id, predictions):     \n",
    "    result = {\n",
    "        'user_id': user_id,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "    with open('result.json', 'w') as outfile:\n",
    "            json.dump(result, outfile, indent=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ides(movies):\n",
    "    ides = {}\n",
    "    \n",
    "    API_ENDPOINT = \"https://www.wikidata.org/wiki/Special:ItemByTitle\"     \n",
    "    params = {\n",
    "     'site' : 'enwiki'\n",
    "    }\n",
    "        \n",
    "    for movie in movies:\n",
    "        params['page'] = movie['name']\n",
    "        \n",
    "        res = requests.get(API_ENDPOINT, params=params, allow_redirects=False)\n",
    "        if 'Location' in res.headers:\n",
    "            ides[movie['name']] = res.headers['Location'][len('https://www.wikidata.org/wiki/'):]\n",
    "    return ides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_to_wikidata(id):\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "    spaqrql_query = \"\"\"\n",
    "    SELECT ?movie ?publication_date\n",
    "    WHERE \n",
    "    {\n",
    "        {SELECT ?required_year\n",
    "        WHERE\n",
    "        {\n",
    "          wd:\"\"\" + id + \"\"\" wdt:P577 ?publication_date.\n",
    "          BIND(str(YEAR(?publication_date)) AS ?required_year).\n",
    "        }\n",
    "        ORDER BY ASC(?required_year) LIMIT 1}\n",
    "\n",
    "      ?movie wdt:P31 wd:Q11424;\n",
    "             wdt:P577 ?publication_date.\n",
    "\n",
    "      BIND(str(YEAR(?publication_date)) AS ?publication_year).\n",
    "      FILTER (?publication_year = ?required_year).\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    sparql.setQuery(spaqrql_query)\n",
    "\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies_with_same_year(id):\n",
    "    response = request_to_wikidata(id)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "User ID:  15\n",
      "1512 World of Apu, The (Apur Sansar) (1959)                       4.287\n",
      "853  Braindead (1992)                                             4.285\n",
      "530  Man Who Would Be King, The (1975)                            4.242\n",
      "837  Meet John Doe (1941)                                         4.043\n",
      "198  Nikita (La Femme Nikita) (1990)                              4.041\n"
     ]
    }
   ],
   "source": [
    "user_id = input('ID: ')\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {\n",
    "    'name': 'cosine', \n",
    "    'user_based': True, \n",
    "    'min_support': min_movies\n",
    "}\n",
    "algo = KNNWithMeans(k=4, min_k=k, sim_options=sim_options, verbose=True)\n",
    "algo.fit(trainset)\n",
    "\n",
    "\n",
    "testset = trainset.build_anti_testset()\n",
    "testset = list(filter(lambda x: x[0] == user_id, testset))\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "\n",
    "top_n = get_top_n(predictions)\n",
    "top_n = top_n[user_id]\n",
    " \n",
    "movie_names = read_item_names()\n",
    "\n",
    "predictions = []\n",
    "for movie_rid, rating in top_n:\n",
    "    prediction = {}\n",
    "    prediction['id'] = movie_rid\n",
    "    prediction['name'] = str(movie_names[movie_rid][0])\n",
    "    prediction['rating'] = rating\n",
    "    \n",
    "    predictions.append(prediction)\n",
    "    \n",
    "print_to_console(user_id, predictions)\n",
    "print_to_file(user_id, predictions)\n",
    "\n",
    "ides = load_ides(predictions)\n",
    "print(ides)\n",
    "for movie_name, id in ides.values():\n",
    "    load_movies_with_same_year(id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
